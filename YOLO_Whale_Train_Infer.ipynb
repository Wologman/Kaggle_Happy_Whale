{"cells":[{"cell_type":"markdown","metadata":{"id":"-9h7w1eBGohj"},"source":["<center><h1>YOLO Object Detector for Whale & Dolphin Images</h1></center>\n","\n","# Introduction\n","\n","üê† Drived from various other notebooks, I've only set this up for Co-lab.  Maybe next time will add options for kaggle or running on my own GPU.  \n","\n","[Great-Barrier-Reef: YOLOv5 train üåä](https://www.kaggle.com/awsaf49/great-barrier-reef-yolov5-train), \n","\n","[Great-Barrier-Reef: YOLOv5 [infer] üåä](https://www.kaggle.com/awsaf49/great-barrier-reef-yolov5-infer)\n","\n","[official YOLOv5 user notebook on Kaggle by Ultralytics](https://www.kaggle.com/ultralytics/yolov5). Full tutorial on how to get started. \n","\n","[And this one putting them together by Andrada Oleanu](https://www.kaggle.com/andradaolteanu/greatbarrierreef-yolo-full-guide-train-infer)\n","\n","[And this one also handy](https://blog.paperspace.com/train-yolov5-custom-data/)\n","\n","üê† **YOLO Explained**\n","\n","1. The image is split in a grid that has the same dimension for each \"tile\".\n","2. We add the bounding boxes that identify each object. The bbox has the following format: `[width, height, class, bx, by]`, where `[bx, by]` represents the center of the object.\n","3. Intersection Over Union: this technique is used so the bounding box \"catches\" the object fully (and doesn't leave any part of it uncovered, neither it is too large for the object). The `IOU=1` if the predicted and actual box are identical.\n","\n","<center><img src=\"https://i.imgur.com/Ce1sfqj.png\" width=700></center>\n","\n","*Source: [here](https://www.section.io/engineering-education/introduction-to-yolo-algorithm-for-object-detection/)*\n","\n","### ‚¨á Libraries and Dependencies Below"]},{"cell_type":"markdown","metadata":{"id":"2dzkkOml4B-D"},"source":["## II. YOLOv5 Setup\n","\n","To use the model we need to have the following:\n","* Yolov5 Repository ([available in this dataset by Awsaf](https://www.kaggle.com/awsaf49/yolov5-lib-ds))\n","* Python 3\n","* PyTorch\n","* CUDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1536,"status":"ok","timestamp":1649145278714,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"},"user_tz":-720},"id":"0kthRpTJGohn","outputId":"eb31f406-6912-4ae2-b9cf-6dac0629619a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Running on Colab\n","The project folder is: /content/drive/My Drive/Colab Notebooks/Kaggle/Happy_Whale\n","Not connected to a GPU\n","Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["# Standard Libraries\n","import os\n","import sys\n","#import torch\n","import time\n","import random\n","import shutil\n","import yaml\n","from tqdm import tqdm\n","import warnings\n","import cv2\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.patches as patches\n","import matplotlib.pyplot as plt\n","from IPython.display import display_html\n","from pathlib import Path\n","\n","#Check for the environment\n","IN_COLAB = 'google.colab' in sys.modules  #Checking if this is running in Colab\n","IN_KAGGLE = os.environ.get('PWD') == '/kaggle/working'\n","\n","if (IN_COLAB):\n","  root = Path(os.getcwd())\n","  project_folder = root / 'drive/My Drive/Colab Notebooks/Kaggle/Happy_Whale'\n","  data_folder = project_folder / 'yolo_data'\n","  image_folder = data_folder / 'images'\n","  print(\"Running on Colab\")\n","  print('The project folder is:', project_folder)\n","\n","  gpu_info = !nvidia-smi    \n","  gpu_info = '\\n'.join(gpu_info)\n","  if gpu_info.find('failed') >= 0:\n","    print('Not connected to a GPU')\n","  else:\n","    print(gpu_info)\n","\n","  from psutil import virtual_memory\n","  ram_gb = virtual_memory().total / 1e9\n","  print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","  if ram_gb < 20:\n","    print('Not using a high-RAM runtime')\n","  else:\n","    print('You are using a high-RAM runtime!')\n","\n","\n","#if IN_KAGGLE:\n","#    print(\"We are running on a Kaggle Server\")\n","\n","#if not IN_COLAB or IN_KAGGLE:   \n","#    IN_OTHER = True\n","#    print(\"Running on a machine with personalised directory structures\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1649145278714,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"},"user_tz":-720},"id":"TyxX4DFlWUsB","outputId":"4de2cae8-9d69-40e7-9b8b-508def4980ed"},"outputs":[{"output_type":"stream","name":"stdout","text":["Initial Working directory:  /content\n","Current working directory: /content/drive/My Drive/Colab Notebooks/Kaggle/Happy_Whale/yolov5\n"]}],"source":["if IN_COLAB:\n","  from google.colab import drive\n","  pro_dir = Path('drive/My Drive/Colab Notebooks/') / project_folder\n","  if not os.path.isdir(project_folder):    # Just checking if mounted already\n","    drive.mount('/content/drive')   \n","\n","# if IN_OTHER:\n","#   PRO_DIR = Path(os.path.realpath('__file__')) # For working on a local machine \n","\n","print('Initial Working directory: ', os.getcwd()) # Reference subdirectories  PRO_DIR / <MY_DIR_NAME>\n","os.chdir(project_folder / 'yolov5')\n","print(\"Current working directory: {0}\".format(os.getcwd()))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZxQt5nRSvqqb","executionInfo":{"status":"ok","timestamp":1649145283623,"user_tz":-720,"elapsed":1754,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"}},"outputId":"68f17be0-d9a6-4e78-b7c4-af476ff1330e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setup complete. Using torch 1.10.0+cu111 CPU\n"]}],"source":["# install YOLO dependencies as necessary\n","%pip install -qr requirements.txt  \n","import torch\n","from IPython.display import Image, clear_output  # to display images\n","#from utils.google_utils import gdrive_download  # to download models/datasets\n","\n","#from yolov5 import utils\n","#display = utils.notebook_init()  # I presume this is a kaggle thing\n","\n","# clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5po_1cCjc4vb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649145288838,"user_tz":-720,"elapsed":5220,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"}},"outputId":"d598b7f8-2b8c-4e40-c9be-b9fd1d0132db"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwologman\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":6}],"source":["#Dependencies and setup\n","if IN_COLAB:\n","  !pip install wandb -qqq\n","\n","import wandb\n","\n","# Log in to your W&B account\n","wandb.login()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m03tD3oOjwbi","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1649145288840,"user_tz":-720,"elapsed":27,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"}},"outputId":"43d82927-5fd2-4ac5-c3be-b02e9ce863a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m\u001b[94mCurrent Working Directory\u001b[0m /content/drive/MyDrive/Colab Notebooks/Kaggle/Happy_Whale/yolov5\n","\u001b[1m\u001b[94mNotebook Color Scheme:\u001b[0m\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x72 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAWAAAABICAYAAADI6S+jAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAB90lEQVR4nO3ZMUpcURiG4XNVEDEYDZnaFcQqO9AiAXfjQuyzgiwipLbQBUiqFGkSIRAlTYQ/vSh4YU6+mZPnKS/D8P0MvMWdqaoaAP/eRnoAwP9KgAFCBBggRIABQgQYIESAAUK25nx4Y/tFbe4e9NqSt7OXXtDVy50/6Qnd7A/+29XtfXpCV3e/fqcndPX955ebqlo8fD4rwJu7B+3VydnyVq2YOjpOT+jq9M239IRuTo/epSd0df/pR3pCVxefr9ITujr/+P7rY8+9ggAIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggBABBggRYIAQAQYIEWCAEAEGCBFggJCpqp7/4Wm6ba1d95sT97q1dpMe0cnIt7XmvnU3+n2HVbV4+HBr5pdcV9XbJQ1aOdM0XY5638i3tea+dTf6fU/xCgIgRIABQuYG+EOXFatj5PtGvq0196270e971Kw/4QBYHq8gAEIEGCBEgAFCBBggRIABQv4CMkFKAKPc+fYAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}],"source":["# Environment check\n","warnings.filterwarnings(\"ignore\")\n","os.environ[\"WANDB_SILENT\"] = \"true\"\n","CONFIG = {'competition': 'greatReef', '_wandb_kernel': 'aot'}\n","\n","# üêù Secrets  (Kaggle only)\n","#from kaggle_secrets import UserSecretsClient\n","#user_secrets = UserSecretsClient()\n","#secret_value_0 = user_secrets.get_secret(\"wandb\")\n","#! wandb login $secret_value_0\n","\n","# Custom colors     color class used here is ANSI escape code coloring, for coloring in terminal windows.  \n","class color:\n","    S = '\\033[1m' + '\\033[94m'\n","    E = '\\033[0m'\n","    \n","my_colors = [\"#16558F\", \"#1583D2\", \"#61B0B7\", \"#ADDEFF\", \"#A99AEA\", \"#7158B7\"]\n","print(color.S+\"Current Working Directory\"+color.E, os.getcwd())\n","print(color.S+\"Notebook Color Scheme:\"+color.E)\n","sns.palplot(sns.color_palette(my_colors))"]},{"cell_type":"markdown","metadata":{"id":"IqZflyTxGohp"},"source":["### ‚¨á Helper Functions Below"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OS4vKaUjGohq"},"outputs":[],"source":["# === üêù W&B ===\n","def save_dataset_artifact(run_name, artifact_name, path):\n","    '''Saves dataset to W&B Artifactory.\n","    run_name: name of the experiment\n","    artifact_name: under what name should the dataset be stored\n","    path: path to the dataset'''\n","    \n","    run = wandb.init(project='g2net', \n","                     name=run_name, \n","                     config=CONFIG, anonymous=\"allow\")\n","    artifact = wandb.Artifact(name=artifact_name, \n","                              type='dataset')\n","    artifact.add_file(path)\n","\n","    wandb.log_artifact(artifact)\n","    wandb.finish()\n","    print(\"Artifact has been saved successfully.\")\n","    \n","    \n","def create_wandb_plot(x_data=None, y_data=None, x_name=None, y_name=None, title=None, log=None, plot=\"line\"):\n","    '''Create and save lineplot/barplot in W&B Environment.\n","    x_data & y_data: Pandas Series containing x & y data\n","    x_name & y_name: strings containing axis names\n","    title: title of the graph\n","    log: string containing name of log'''\n","    \n","    data = [[label, val] for (label, val) in zip(x_data, y_data)]\n","    table = wandb.Table(data=data, columns = [x_name, y_name])\n","    \n","    if plot == \"line\":\n","        wandb.log({log : wandb.plot.line(table, x_name, y_name, title=title)})\n","    elif plot == \"bar\":\n","        wandb.log({log : wandb.plot.bar(table, x_name, y_name, title=title)})\n","    elif plot == \"scatter\":\n","        wandb.log({log : wandb.plot.scatter(table, x_name, y_name, title=title)})\n","        \n","        \n","def create_wandb_hist(x_data=None, x_name=None, title=None, log=None):\n","    '''Create and save histogram in W&B Environment.\n","    x_data: Pandas Series containing x values\n","    x_name: strings containing axis name\n","    title: title of the graph\n","    log: string containing name of log'''\n","    \n","    data = [[x] for x in x_data]\n","    table = wandb.Table(data=data, columns=[x_name])\n","    wandb.log({log : wandb.plot.histogram(table, x_name, title=title)})"]},{"cell_type":"markdown","metadata":{"id":"-2vpxn9DGohq"},"source":["# Set up File structure for Colab.\n","\n","In Kaggle by default the working directory is `/kaggle/working`. Whenever you want to `save` a file, the output goes there.\n","\n","The default working directory in Colab is `/content`. But this is a pain because the data gets lost at the end of the session.  So I'm trying to work from a project directory within g-drive, and include the yolov5 repo in there. So in this case `/content/drive/My Drive/Colab Notebooks/Kaggle/Happy_Whale/` \n","\n","\n","üê† The idea here is to create 2 more folders: \n","* `/<projec directory>/data/images` - folder where we will store training images, with 3 sub-folders train, val and test.\n","* `/<projec directory>/data/labels` - folder where we will store labels (annotations) found within these images, with 3 sub-folders."]},{"cell_type":"markdown","metadata":{"id":"hOeGgapVGohu"},"source":["## II. The Labels\n","\n","In this case I've created the annotations in CVAT, and exported in YOLO 1.1 format. It may also be handy sometimes to use the COCO format, so I leave this converter here for future projects. Also it's handy to do the reverse to display with openCV & Pillow.\n","\n","For COCO to YOLO, we need to go from `[xmin, ymin, w, h]` to the corresponding yolo format `[xmid, ymid, w, h]`.\n","\n","<center><img src=\"https://i0.wp.com/prabhjotkaurgosal.com/wp-content/uploads/2021/03/image.png?resize=1536%2C419&ssl=1\" width=900></center>\n","\n","*Source: [here](https://prabhjotkaurgosal.com/weekly-learnings/weekly-learning-blogs/)*"]},{"cell_type":"markdown","metadata":{"id":"cHzt0FYAGohv"},"source":["### Annotation\n","\n","üê†  In the YOLO labeling format, a `.txt` file with the same name is created for each image file in the same directory. Each `.txt` file contains the annotations for the corresponding image file, that is:\n","* *object class* - not applicable in our case, so it will be always set to 0\n","* *YOLO bbox* - the YOLO bboxes we have just created"]},{"cell_type":"markdown","metadata":{"id":"Ic0elAtNGohw"},"source":["# Step 3. YOLO Configuration\n","\n","## I. Splitting the Data\n","\n","üê† I have split the training data into 3 parts (I messed this up, will re-do later!), later all the data will be put through inferance for use in the next step of the competition:\n","* `train_data`: 1638 hand annotated images from CVAT, minus the test images\n","*  `val_data`:  307 randomly sampled from the total\n","* `eval_data`: 103 randomly sampled from the total for performance evaluation\n","* `infer_data_1`: The competition dataset of 51,000 samples\n","* `infer_data_2`: The competition test dataset, 28,000 samples\n","\n","Also needed is a .yml file, and text files pointing to the data filepaths.  Best to make these here in this notebook so the filepaths are up to date with what ever system this notebook is running in."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0mZF9-mZ8are"},"outputs":[],"source":["#### Create train, val and test path data .txt files here\n","\n","image_types = ['train', 'val', 'test']\n","text_files = ['train_images.txt', 'val_images.txt', 'test_images.txt']\n","\n","for image_type, text_file in zip(image_types, text_files):\n","  with open(data_folder / text_file, \"w\") as file:\n","    for name in os.listdir(image_folder / image_type):\n","      path = image_folder / image_type /  name\n","      file.write(path.as_posix() + \"\\n\")    #need to convert to string?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_MAJ9-YJ8afI"},"outputs":[],"source":["##### Create configuration .yml   For the destination YOLO will be run.\n","\n","#'path': 'Kaggle/Happy_Whale/',  # didn't see why this was needed\n","\n","config = {'train': '/content/drive/MyDrive/Colab Notebooks/Kaggle/Happy_Whale/yolo_data/train_images.txt',\n","         'val': '/content/drive/MyDrive/Colab Notebooks/Kaggle/Happy_Whale/yolo_data/val_images.txt',\n","          'test': '/content/drive/MyDrive/Colab Notebooks/Kaggle/Happy_Whale/yolo_data/test_images.txt',\n","          'nc': 1,\n","          'names': ['catacean']}\n","\n","with open(data_folder / 'happy_whale.yaml', \"w\") as file:\n","    yaml.dump(config, file, default_flow_style=False)"]},{"cell_type":"markdown","metadata":{"id":"qCqAILP8Gohy"},"source":["# Step 4. YOLOv5 Training\n","\n","## I. YOLOv5\n","\n","YOLO's first model was released in 2016, followed by YOLOv2 in 2017 and YOLOv3 in 2018. In 2020 [Joseph Redmon](https://machinelearningknowledge.ai/introduction-to-yolov5-object-detection-with-tutorial/#Introduction) stepped out from the project and his work was further improved by Alexey Bochkovskiy who produced YOLOv4 in 2020.\n","\n","**YOLOv5** is the next controversial member of the YOLO family released in 2020 by the company Ultranytics just a few days after YOLOv4 ([source here](https://machinelearningknowledge.ai/introduction-to-yolov5-object-detection-with-tutorial/#Introduction)). It is controversial because there has never been any paper released to back up the model, nevertheless it works!\n","\n","<center><img src=\"https://machinelearningknowledge.ai/wp-content/uploads/2021/06/YOLOv5-Architecture.jpg\" width=700></center>\n","\n","*[Source here](https://www.researchgate.net/publication/349299852_A_Forest_Fire_Detection_System_Based_on_Ensemble_Learning)*\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hHnQGHGbGohy"},"outputs":[],"source":["# I have moved the dependency setup to the top"]},{"cell_type":"markdown","metadata":{"id":"EJ4WnJa-Gohy"},"source":["## III. Training\n","\n","* üêù **Note**: YOLOv5 **connects automatically to your W&B account** and tracks the runs and progress there, so you do not need to log in anything during training.\n","\n","üê† Within the training cell:\n","* specify the dataset - `happy_whale.yaml`\n","* batch size\n","* image size\n","* pretrained yolov5 weights (`yolov5s.pt`, `yolov5m.pt` etc.)\n","\n","**There are multiple models you could try:**\n","\n","<center><img src=\"https://github.com/ultralytics/yolov5/releases/download/v1.0/model_comparison.png\" width=700></center>\n","\n","*[Source here](https://docs.ultralytics.com/tutorials/train-custom-datasets/) - [full table with all available options here](https://github.com/ultralytics/yolov5#pretrained-checkpoints)*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XpIA_xKNGohy"},"outputs":[],"source":["# --- PARAMETERS ---\n","# These are just small samples, so the notebook runs faster\n","SIZE = 512\n","BATCH_SIZE = 64\n","EPOCHS = 70\n","MODEL = \"yolov5m\"\n","WORKERS = 4\n","PROJECT = \"HappyWhale\"\n","RUN_NAME = f\"{MODEL}_size{SIZE}_epochs{EPOCHS}_batch{BATCH_SIZE}_simple\"\n","# ------------------"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqdWs5fPAR2J","executionInfo":{"status":"ok","timestamp":1649145288841,"user_tz":-720,"elapsed":18,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"}},"outputId":"f61f43e9-911a-496d-fe2b-b1ef6dd121fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m\u001b[94mCurrent Working Directory\u001b[0m /content/drive/My Drive/Colab Notebooks/Kaggle/Happy_Whale/yolov5\n"]}],"source":["print(color.S+\"Current Working Directory\"+color.E, os.getcwd())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"VDryN7AFGohy","executionInfo":{"status":"ok","timestamp":1649145288842,"user_tz":-720,"elapsed":17,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"}},"outputId":"aa17c334-ac17-4cae-b7f5-7c62d362a925"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"!python train.py --img {SIZE}                --batch {BATCH_SIZE}                --epochs {EPOCHS}                --data /content/drive/MyDrive/Colab' 'Notebooks/Kaggle/Happy_Whale/yolo_data/happy_whale.yaml                --weights {MODEL}.pt                --workers {WORKERS}                --project {PROJECT}                --name {RUN_NAME}                --exist-ok\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":14}],"source":["# Training   Comment this out when not re-training\n","!python train.py --img {SIZE}\\\n","                --batch {BATCH_SIZE}\\\n","                --epochs {EPOCHS}\\\n","                --data /content/drive/MyDrive/Colab' 'Notebooks/Kaggle/Happy_Whale/yolo_data/happy_whale.yaml\\\n","                --weights {MODEL}.pt\\\n","                --workers {WORKERS}\\\n","                --project {PROJECT}\\\n","                --name {RUN_NAME}\\\n","                --exist-ok"]},{"cell_type":"markdown","metadata":{"id":"BsE86zf5Gohz"},"source":["## IV. Inspecting the results\n","\n","All training results are saved to `content/yolov5/runs/train/` with incrementing run directories (first run is `exp`, then `exp2`, `exp3` and so on).\n","\n","> üêù **Note**: in this notebooks, `runs` is actually the folder `GreatBarrierReef`, as I am saving the logs during training within [my personal Dashboard for this competition here](https://wandb.ai/andrada/GreatBarrierReef?workspace=user-andrada). This way I can properly *name* the experiments - so, instead of having exp1, exp2 etc, I can have a proper name that will better indicate the experiment I am making. Also, **all data in this folder can be viewed in the W&B Dashboard**.\n","\n","<center><img src=\"https://i.imgur.com/n8elExY.png\" width=700></center>\n","\n","üê† Below it's a view of the new files created after training:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXtX0JIqGohz","executionInfo":{"status":"ok","timestamp":1649145288842,"user_tz":-720,"elapsed":16,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"}},"outputId":"0e9a9c5c-8131-4a54-9da6-509ea166c36f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['weights',\n"," 'hyp.yaml',\n"," 'opt.yaml',\n"," 'labels_correlogram.jpg',\n"," 'labels.jpg',\n"," 'train_batch0.jpg',\n"," 'train_batch1.jpg',\n"," 'train_batch2.jpg',\n"," 'results.csv',\n"," 'val_batch0_labels.jpg',\n"," 'val_batch0_pred.jpg',\n"," 'val_batch1_labels.jpg',\n"," 'val_batch1_pred.jpg',\n"," 'PR_curve.png',\n"," 'F1_curve.png',\n"," 'val_batch2_pred.jpg',\n"," 'val_batch2_labels.jpg',\n"," 'P_curve.png',\n"," 'R_curve.png',\n"," 'confusion_matrix.png',\n"," 'results.png',\n"," 'events.out.tfevents.1649108527.ec0699ebe5ab.2084.0']"]},"metadata":{},"execution_count":15}],"source":["# Run details\n","os.listdir(f\"{PROJECT}/{RUN_NAME}\")"]},{"cell_type":"markdown","metadata":{"id":"V72z-0wEGohz"},"source":["# Step 5. Inference"]},{"cell_type":"code","source":["os.chdir(project_folder)\n","print(color.S+\"Current Working Directory\"+color.E, os.getcwd())"],"metadata":{"id":"-00D5LZ96z8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# --- PARAMETERS ---\n","SOURCE = \"yolo_data/happy_whale.yaml\"\n","WEIGHTS = \"yolov5/HappyWhale/yolov5m_size512_epochs50_batch32_simple/weights/best.pt\"\n","NAME = \"happy_whale\"   # might need to be --name  for test metrics\n","IOU = 0.25\n","IMG = 516\n","TASK = \"test\"\n","# ------------------"],"metadata":{"id":"uatX0KrbreuL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mbMDOmfCGoh1","executionInfo":{"status":"ok","timestamp":1649149274042,"user_tz":-720,"elapsed":123108,"user":{"displayName":"Olly Powell","userId":"04453969708292757168"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"16830196-3b61-4299-d6c6-4197e1b3ca22"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=yolo_data/happy_whale.yaml, weights=['yolov5/HappyWhale/yolov5m_size512_epochs50_batch32_simple/weights/best.pt'], batch_size=32, imgsz=516, conf_thres=0.001, iou_thres=0.25, task=test, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=happy_whale, exist_ok=False, half=False, dnn=False\n","fatal: cannot change to '/content/drive/MyDrive/Colab': No such file or directory\n","YOLOv5 üöÄ 2022-3-24 torch 1.10.0+cu111 CPU\n","\n","Fusing layers... \n","Model summary: 290 layers, 20852934 parameters, 0 gradients, 47.9 GFLOPs\n","WARNING: --img-size 516 must be multiple of max stride 32, updating to 544\n","\u001b[34m\u001b[1mtest: \u001b[0mScanning '/content/drive/MyDrive/Colab Notebooks/Kaggle/Happy_Whale/yolo_data/test_images' images and labels...103 found, 0 missing, 1 empty, 0 corrupt: 100% 103/103 [00:56<00:00,  1.81it/s]\n","\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /content/drive/MyDrive/Colab Notebooks/Kaggle/Happy_Whale/yolo_data/test_images.cache\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:57<00:00, 14.45s/it]\n","                 all        103        113      0.936      0.903      0.939      0.835\n","Speed: 3.8ms pre-process, 552.2ms inference, 0.8ms NMS per image at shape (32, 3, 544, 544)\n","Results saved to \u001b[1myolov5/runs/val/happy_whale\u001b[0m\n"]}],"source":["!python yolov5/val.py \\\n","--data {DATA} \\\n","--weights {WEIGHTS} \\\n","--imgsz {IMG} \\\n","--iou-thres {IOU} \\\n","--task {TASK} \\\n","--name {NAME}"]},{"cell_type":"markdown","metadata":{"id":"CfBsitBbGoh1"},"source":["### üêù W&B Dashboard\n","\n","> My [W&B Dashboard](https://wandb.ai/wologman).\n","\n","<center><video src=\"https://i.imgur.com/z3d7smf.mp4\" width=800 controls></center>\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"YOLO_Whale_Train_Infer.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":0}